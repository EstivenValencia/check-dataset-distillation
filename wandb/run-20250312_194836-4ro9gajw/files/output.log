Hyper-parameters:
 {'_wandb': {}, 'dataset': 'CIFAR100', 'subset': 'imagenette', 'model': 'ConvNet', 'res': 128, 'ipc': 10, 'eval_mode': 'S', 'num_eval': 5, 'eval_it': 100, 'epoch_eval_train': 1000, 'Iteration': 5000, 'lr_img': 1000.0, 'lr_lr': 1e-05, 'lr_teacher': 0.01, 'lr_init': 0.01, 'batch_real': 256, 'batch_syn': 1000, 'batch_train': 256, 'pix_init': 'real', 'dsa': True, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'cifar100/images_db', 'buffer_path': 'cifar100/expertdb', 'expert_epochs': 2, 'syn_steps': 30, 'max_start_epoch': 15, 'zca': True, 'load_all': False, 'no_aug': False, 'texture': False, 'canvas_size': 2, 'canvas_samples': 1, 'max_files': None, 'max_experts': None, 'force_save': False, 'device': 'cuda', 'zca_trans': ZCAWhitening(), 'im_size': [32, 32], 'dc_aug_param': None, 'dsa_param': <utils.ParamDiffAug object at 0x7f516778fd50>, 'distributed': False}
Evaluation model pool:  ['ConvNet']
BUILDING DATASET
  0%|                                                                                                                                                                           | 0/50000 [00:00<?, ?it/s]/data/home/rtabares/.juan/mtt-distillation/distill.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_all.append(class_map[torch.tensor(sample[1]).item()])
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 55280.43it/s]
50000it [00:00, 4208782.21it/s]
class c = 0: 500 real images
class c = 1: 500 real images
class c = 2: 500 real images
class c = 3: 500 real images
class c = 4: 500 real images
class c = 5: 500 real images
class c = 6: 500 real images
class c = 7: 500 real images
class c = 8: 500 real images
class c = 9: 500 real images
class c = 10: 500 real images
class c = 11: 500 real images
class c = 12: 500 real images
class c = 13: 500 real images
class c = 14: 500 real images
class c = 15: 500 real images
class c = 16: 500 real images
class c = 17: 500 real images
class c = 18: 500 real images
class c = 19: 500 real images
class c = 20: 500 real images
class c = 21: 500 real images
class c = 22: 500 real images
class c = 23: 500 real images
class c = 24: 500 real images
class c = 25: 500 real images
class c = 26: 500 real images
class c = 27: 500 real images
class c = 28: 500 real images
class c = 29: 500 real images
class c = 30: 500 real images
class c = 31: 500 real images
class c = 32: 500 real images
class c = 33: 500 real images
class c = 34: 500 real images
class c = 35: 500 real images
class c = 36: 500 real images
class c = 37: 500 real images
class c = 38: 500 real images
class c = 39: 500 real images
class c = 40: 500 real images
class c = 41: 500 real images
class c = 42: 500 real images
class c = 43: 500 real images
class c = 44: 500 real images
class c = 45: 500 real images
class c = 46: 500 real images
class c = 47: 500 real images
class c = 48: 500 real images
class c = 49: 500 real images
class c = 50: 500 real images
class c = 51: 500 real images
class c = 52: 500 real images
class c = 53: 500 real images
class c = 54: 500 real images
class c = 55: 500 real images
class c = 56: 500 real images
class c = 57: 500 real images
class c = 58: 500 real images
class c = 59: 500 real images
class c = 60: 500 real images
class c = 61: 500 real images
class c = 62: 500 real images
class c = 63: 500 real images
class c = 64: 500 real images
class c = 65: 500 real images
class c = 66: 500 real images
class c = 67: 500 real images
class c = 68: 500 real images
class c = 69: 500 real images
class c = 70: 500 real images
class c = 71: 500 real images
class c = 72: 500 real images
class c = 73: 500 real images
class c = 74: 500 real images
class c = 75: 500 real images
class c = 76: 500 real images
class c = 77: 500 real images
class c = 78: 500 real images
class c = 79: 500 real images
class c = 80: 500 real images
class c = 81: 500 real images
class c = 82: 500 real images
class c = 83: 500 real images
class c = 84: 500 real images
class c = 85: 500 real images
class c = 86: 500 real images
class c = 87: 500 real images
class c = 88: 500 real images
class c = 89: 500 real images
class c = 90: 500 real images
class c = 91: 500 real images
class c = 92: 500 real images
class c = 93: 500 real images
class c = 94: 500 real images
class c = 95: 500 real images
class c = 96: 500 real images
class c = 97: 500 real images
class c = 98: 500 real images
class c = 99: 500 real images
real images channel 0, mean = 0.0000, std = 0.2707
real images channel 1, mean = 0.0000, std = 0.2555
real images channel 2, mean = 0.0000, std = 0.2647
/data/home/rtabares/.juan/mtt-distillation/distill.py:111: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)
  label_syn = torch.tensor([np.ones(args.ipc,dtype=np.int_)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
initialize synthetic data from random real images
[2025-03-12 19:48:38] training begins
Expert Dir: cifar100/expertdb/CIFAR100/ConvNet
loading file cifar100/expertdb/CIFAR100/ConvNet/replay_buffer_5.pt
-------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
DSA augmentation strategy:
 color_crop_cutout_flip_scale_rotate
DSA augmentation parameters:
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'ratio_noise': 0.05, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
  0%|▏                                                                                                                                                                   | 1/1001 [00:01<20:15,  1.22s/it]/data/home/rtabares/.juan/env/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [01:01<00:00, 16.32it/s]
[2025-03-12 19:49:41] Evaluate_00: epoch = 1000 train time = 61 s train loss = 0.009295 train acc = 0.9990, test acc = 0.1792
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [01:01<00:00, 16.39it/s]
[2025-03-12 19:50:42] Evaluate_01: epoch = 1000 train time = 61 s train loss = 0.010766 train acc = 1.0000, test acc = 0.1821
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [01:00<00:00, 16.56it/s]
[2025-03-12 19:51:42] Evaluate_02: epoch = 1000 train time = 60 s train loss = 0.023484 train acc = 1.0000, test acc = 0.1819
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [01:01<00:00, 16.40it/s]
[2025-03-12 19:52:43] Evaluate_03: epoch = 1000 train time = 61 s train loss = 0.012067 train acc = 1.0000, test acc = 0.1815
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [01:00<00:00, 16.54it/s]
[2025-03-12 19:53:44] Evaluate_04: epoch = 1000 train time = 60 s train loss = 0.006837 train acc = 1.0000, test acc = 0.1811
Evaluate 5 random ConvNet, mean = 0.1812 std = 0.0010
-------------------------
Traceback (most recent call last):
  File "/data/home/rtabares/.juan/mtt-distillation/distill.py", line 477, in <module>
    main(args)
  File "/data/home/rtabares/.juan/mtt-distillation/distill.py", line 368, in main
    grad = torch.autograd.grad(ce_loss, student_params[-1], create_graph=True)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/rtabares/.juan/env/lib/python3.11/site-packages/torch/autograd/__init__.py", line 496, in grad
    result = _engine_run_backward(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/rtabares/.juan/env/lib/python3.11/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 47.45 GiB of which 437.50 MiB is free. Including non-PyTorch memory, this process has 47.02 GiB memory in use. Of the allocated memory 45.22 GiB is allocated by PyTorch, and 653.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
